{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling com LangChain\n",
    "<img src=\"https://python.langchain.com/assets/images/tool_call-8d4a8b18e90cacd03f62e94071eceace.png\">\n",
    "\n",
    "Neste notebook, vamos aprender como usar modelos de chat para chamar ferramentas (tools) usando a LangChain. Este √© um conceito poderoso que permite que modelos de linguagem interajam com fun√ß√µes definidas.\n",
    "\n",
    "## O que √© Tool Calling?\n",
    "\n",
    "Tool Calling permite que um modelo de chat responda a um prompt chamando uma \"ferramenta\". √â importante notar que:\n",
    "- O modelo n√£o executa diretamente a a√ß√£o\n",
    "- O modelo apenas gera os argumentos para a ferramenta\n",
    "- A execu√ß√£o real da ferramenta √© controlada pelo usu√°rio\n",
    "\n",
    "## Pr√©-requisitos\n",
    "Antes de come√ßarmos, vamos instalar as bibliotecas necess√°rias:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo Schemas de Ferramentas\n",
    "\n",
    "Existem v√°rias maneiras de definir schemas para nossas ferramentas. Vamos explorar tr√™s abordagens diferentes:\n",
    "1. Usando fun√ß√µes Python\n",
    "2. Usando classes Pydantic\n",
    "3. Usando TypedDict\n",
    "\n",
    "## 1. Fun√ß√µes Python\n",
    "Primeiro, vamos ver como definir ferramentas usando fun√ß√µes Python simples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv  \n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "OPENAI_MODEL_NAME = os.getenv('OPENAI_MODEL_NAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado da ferramenta `multiply`: 39\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv  \n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# Registrar as ferramentas\n",
    "tools = [add, multiply]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Vincular o LLM √†s ferramentas\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Pergunta ao LLM\n",
    "query = \"Quanto √© 3 * 13?\"\n",
    "response = llm_with_tools.invoke(query)\n",
    "\n",
    "# üîπ Verificando se houve chamadas de ferramentas\n",
    "if response.tool_calls:\n",
    "    for tool_call in response.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]  # Nome da ferramenta que foi chamada\n",
    "        tool_args = tool_call[\"args\"]  # Argumentos que o LLM passou para a ferramenta\n",
    "\n",
    "        # üîπ Executa a ferramenta correta com os argumentos extra√≠dos\n",
    "        if tool_name == \"multiply\":\n",
    "            result = multiply.invoke(tool_args)\n",
    "        elif tool_name == \"add\":\n",
    "            result = add.invoke(tool_args)\n",
    "        \n",
    "        print(f\"Resultado da ferramenta `{tool_name}`: {result}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Tool chamada: add\n",
      "üîπ Argumentos recebidos: {'number1': 2, 'number2': 2}\n",
      "‚úÖ Resultado da ferramenta `add`: 4\n",
      "[HumanMessage(content='Ol√°, quanto √© 2 + 2?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_wqHDDamt9pis4XTrNR4WptMT', 'function': {'arguments': '{\"number1\":2,\"number2\":2}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 71, 'total_tokens': 91, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d0847346-a63b-4d99-81a2-221c625cd277-0', tool_calls=[{'name': 'add', 'args': {'number1': 2, 'number2': 2}, 'id': 'call_wqHDDamt9pis4XTrNR4WptMT', 'type': 'tool_call'}], usage_metadata={'input_tokens': 71, 'output_tokens': 20, 'total_tokens': 91, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv  \n",
    "from langchain_core.tools import StructuredTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Carregar vari√°veis de ambiente\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "OPENAI_MODEL_NAME = os.getenv('OPENAI_MODEL_NAME')\n",
    "\n",
    "# Defini√ß√£o do esquema de entrada\n",
    "class AddInput(BaseModel):\n",
    "    number1: int = Field(..., description=\"Primeiro n√∫mero inteiro\")\n",
    "    number2: int = Field(..., description=\"Segundo n√∫mero inteiro\")\n",
    "\n",
    "# Fun√ß√£o da ferramenta\n",
    "def add(number1: float, number2: float) -> float:\n",
    "    \"Essa fun√ß√£o faz a somat√≥ria de um number1 mais um number2\"\n",
    "    return number1 + number2\n",
    "\n",
    "# Criar ferramenta usando StructuredTool\n",
    "add_tool = StructuredTool(\n",
    "    name=\"add\",\n",
    "    func=add,\n",
    "    description=\"Essa fun√ß√£o realiza a soma de 2 n√∫meros.\",\n",
    "    args_schema=AddInput  # Define explicitamente os par√¢metros\n",
    ")\n",
    "\n",
    "# Criar LLM e vincul√°-lo √† ferramenta\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "llm_with_tool = llm.bind_tools([add_tool])\n",
    "\n",
    "# Consulta ao LLM\n",
    "query = \"Ol√°, quanto √© 2 + 2?\"\n",
    "\n",
    "\n",
    "messages = [HumanMessage(content=query)]\n",
    "response = llm_with_tool.invoke([HumanMessage(content=query)])\n",
    "\n",
    "\n",
    "messages.append(response)\n",
    "# Verificando chamadas de ferramenta\n",
    "if response.tool_calls:\n",
    "    for tool_call in response.tool_calls:\n",
    "        tool_name = tool_call[\"name\"] \n",
    "        tool_args = tool_call[\"args\"]  \n",
    "        print(f\"üîπ Tool chamada: {tool_name}\")\n",
    "        print(f\"üîπ Argumentos recebidos: {tool_args}\")\n",
    "\n",
    "        if tool_name == \"add\":\n",
    "            result = add_tool.invoke(tool_args)  \n",
    "        \n",
    "        print(f\"‚úÖ Resultado da ferramenta `{tool_name}`: {result}\")\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
